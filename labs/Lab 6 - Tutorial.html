
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Lab 6 Tutorial: Deep Learning with TensorFlow &#8212; ML Engineering</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Lab 7 Tutorial: Deep Learning for text" href="Lab%207%20-%20Tutorial.html" />
    <link rel="prev" title="Lab 4 Tutorial: Data engineering pipelines" href="Lab%204%20-%20Tutorial.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/banner.jpeg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">ML Engineering</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Welcome
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Lab%200%20-%20Prerequisites.html">
   Prerequisites
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Lectures
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/01%20-%20Introduction.html">
   Lecture 1: Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/02%20-%20Linear%20Models.html">
   Lecture 2: Linear models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/03%20-%20Kernelization.html">
   Lecture 3: Kernelization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/04%20-%20Model%20Selection.html">
   Lecture 4: Model Selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/05%20-%20Ensemble%20Learning.html">
   Lecture 5. Ensemble Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/06%20-%20Data%20Preprocessing.html">
   Lecture 6. Data preprocessing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/07%20-%20Bayesian%20Learning.html">
   Lecture 7. Bayesian Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/08%20-%20Neural%20Networks.html">
   Lecture 8. Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/09%20-%20Convolutional%20Neural%20Networks.html">
   Lecture 9: Convolutional Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/10%20-%20Neural%20Networks%20for%20text.html">
   Lecture 10. Neural Networks for text
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Labs
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Lab%201a%20-%20Linear%20Models%20for%20Regression.html">
   Lab 1a: Linear regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Lab%201b%20-%20Linear%20Models%20for%20Classification.html">
   Lab 1b: Linear classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Lab%202%20-%20Kernelization.html">
   Lab 2: Kernelization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Lab%203a%20-%20Model%20Selection.html">
   Lab 3a: Model selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Lab%203b%20-%20Ensembles.html">
   Lab 3b: Ensembles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Lab%204%20-%20Pipelines.html">
   Lab 4:  Data preprocessing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Lab%205%20-%20Bayesian%20learning.html">
   Lab 5: Bayesian models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Lab%206%20-%20Neural%20Networks.html">
   Lab 6: Neural networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Lab%207a%20-%20Convolutional%20Neural%20Networks.html">
   Lab 7a: Convolutional neural nets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Lab%207b%20-%20Neural%20Networks%20for%20text.html">
   Lab 7b: Neural Networks for text
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Lab%208%20-%20AutoML.html">
   Lab 8: AutoML
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/Tutorial%201%20-%20Python.html">
   Python for data analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/Tutorial%202%20-%20Python%20for%20Data%20Analysis.html">
   Python for scientific computing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/Tutorial%203%20-%20Machine%20Learning%20in%20Python.html">
   Machine Learning in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/Tutorial%204%20-%20Decision%20Trees.html">
   Recap: Decision Trees
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/Tutorial%205%20-%20Nearest%20Neighbors.html">
   Recap: k-Nearest Neighbor
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Lab%201%20-%20Tutorial.html">
   Lab 1: Machine Learning with Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Lab%203%20-%20Tutorial.html">
   Lab 3 Tutorial: Model Selection in scikit-learn
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Lab%204%20-%20Tutorial.html">
   Lab 4 Tutorial: Data engineering pipelines
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Lab 6 Tutorial: Deep Learning with TensorFlow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Lab%207%20-%20Tutorial.html">
   Lab 7 Tutorial: Deep Learning for text
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/labs/Lab 6 - Tutorial.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/ml-course/master"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/ml-course/master/issues/new?title=Issue%20on%20page%20%2Flabs/Lab 6 - Tutorial.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/ml-course/master/master?urlpath=tree/labs/Lab 6 - Tutorial.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/ml-course/master/blob/master/labs/Lab 6 - Tutorial.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#running-example">
   Running example
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#preprocessing">
     Preprocessing
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#reshaping">
       Reshaping
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#rescaling">
       Rescaling
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#label-formatting">
       Label formatting
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-test-splits">
     Train-test splits
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#building-sequential-networks">
     Building Sequential networks
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-input-layer">
       The input layer
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#activation-layers">
       Activation layers
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#model-summary">
       Model summary
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#choosing-loss-optimizer-metrics">
     Choosing loss, optimizer, metrics
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training-fitting">
     Training (fitting)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#repeated-fitting">
       Repeated fitting
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tracking-progress">
       Tracking progress
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#predictions-and-evaluations">
     Predictions and evaluations
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#checking-the-learning-curve">
   Checking the learning curve
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#early-stopping">
     Early stopping
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regularization">
   Regularization
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#weight-regularization-weight-decay">
     Weight regularization (weight decay)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dropout">
     Dropout
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#batch-normalization">
     Batch Normalization
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#combining-multiple-regularizers">
       Combining multiple regularizers
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tuning-multiple-hyperparameters">
     Tuning multiple hyperparameters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#further-reading">
     Further reading
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Lab 6 Tutorial: Deep Learning with TensorFlow</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#running-example">
   Running example
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#preprocessing">
     Preprocessing
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#reshaping">
       Reshaping
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#rescaling">
       Rescaling
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#label-formatting">
       Label formatting
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-test-splits">
     Train-test splits
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#building-sequential-networks">
     Building Sequential networks
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-input-layer">
       The input layer
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#activation-layers">
       Activation layers
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#model-summary">
       Model summary
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#choosing-loss-optimizer-metrics">
     Choosing loss, optimizer, metrics
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training-fitting">
     Training (fitting)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#repeated-fitting">
       Repeated fitting
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tracking-progress">
       Tracking progress
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#predictions-and-evaluations">
     Predictions and evaluations
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#checking-the-learning-curve">
   Checking the learning curve
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#early-stopping">
     Early stopping
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regularization">
   Regularization
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#weight-regularization-weight-decay">
     Weight regularization (weight decay)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dropout">
     Dropout
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#batch-normalization">
     Batch Normalization
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#combining-multiple-regularizers">
       Combining multiple regularizers
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tuning-multiple-hyperparameters">
     Tuning multiple hyperparameters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#further-reading">
     Further reading
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="lab-6-tutorial-deep-learning-with-tensorflow">
<h1>Lab 6 Tutorial: Deep Learning with TensorFlow<a class="headerlink" href="#lab-6-tutorial-deep-learning-with-tensorflow" title="Permalink to this headline">¶</a></h1>
<p><strong>Using the Keras API</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Auto-setup when running on Google Colab</span>
<span class="k">if</span> <span class="s1">&#39;google.colab&#39;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">get_ipython</span><span class="p">()):</span>
    <span class="o">!</span>pip install openml

<span class="c1"># General imports</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">openml</span> <span class="k">as</span> <span class="nn">oml</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras</span> <span class="k">as</span> <span class="nn">keras</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="running-example">
<h2>Running example<a class="headerlink" href="#running-example" title="Permalink to this headline">¶</a></h2>
<p>We use the Fashion-MNIST dataset, which consists of 28x28 pixel images of 10 classes of fashion items.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download FMINST data. Takes a while the first time.</span>
<span class="n">mnist</span> <span class="o">=</span> <span class="n">oml</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">get_dataset</span><span class="p">(</span><span class="mi">40996</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">mnist</span><span class="o">.</span><span class="n">default_target_attribute</span><span class="p">,</span> <span class="n">dataset_format</span><span class="o">=</span><span class="s1">&#39;array&#39;</span><span class="p">);</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">70000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
<span class="n">fmnist_classes</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="s2">&quot;T-shirt/top&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s2">&quot;Trouser&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s2">&quot;Pullover&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="s2">&quot;Dress&quot;</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="s2">&quot;Coat&quot;</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span> <span class="s2">&quot;Sandal&quot;</span><span class="p">,</span> 
                  <span class="mi">6</span><span class="p">:</span> <span class="s2">&quot;Shirt&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">:</span> <span class="s2">&quot;Sneaker&quot;</span><span class="p">,</span> <span class="mi">8</span><span class="p">:</span> <span class="s2">&quot;Bag&quot;</span><span class="p">,</span> <span class="mi">9</span><span class="p">:</span> <span class="s2">&quot;Ankle boot&quot;</span><span class="p">}</span>

<span class="c1"># Take some random examples</span>
<span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">randint</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span>  <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">70000</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">gray_r</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">fmnist_classes</span><span class="p">[</span><span class="n">y</span><span class="p">[</span><span class="n">n</span><span class="p">]]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Lab 6 - Tutorial_3_0.png" src="../_images/Lab 6 - Tutorial_3_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(70000, 28, 28)
</pre></div>
</div>
</div>
</div>
<div class="section" id="preprocessing">
<h3>Preprocessing<a class="headerlink" href="#preprocessing" title="Permalink to this headline">¶</a></h3>
<div class="section" id="reshaping">
<h4>Reshaping<a class="headerlink" href="#reshaping" title="Permalink to this headline">¶</a></h4>
<p>To be able to feed this data through the network, the shape of the data must match the shape of the input layer.
For normal dense layers, this will be a ‘flattened’ array. You can use:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.reshape.html">numpy.reshape()</a></p></li>
<li><p><a class="reference external" href="https://keras.io/api/layers/reshaping_layers/">Keras reshaping layers</a>, e.g. <a class="reference external" href="https://keras.io/api/layers/reshaping_layers/flatten/">Flatten</a></p>
<ul>
<li><p>Can also be used to flatten the data at the <em>output</em> of the network</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">70000</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="rescaling">
<h4>Rescaling<a class="headerlink" href="#rescaling" title="Permalink to this headline">¶</a></h4>
<p>Rescaling the data will help training a lot, and lead to faster convergence.
You can use min-max scaling to [0,1] or standardization (mean 0, standard deviation 1).
Note: We’re using a simple division by the maximum possible value. This won’t cause data leakage.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="label-formatting">
<h4>Label formatting<a class="headerlink" href="#label-formatting" title="Permalink to this headline">¶</a></h4>
<p>For multi-class classification, our output layer will usually have one output node per class. Therefore, we need to on-hot-encode the labels. E.g. class ‘4’ becomes [0,0,0,0,1,0,…]</p>
<ul class="simple">
<li><p>Keras has a helper function <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical">to_categorical</a> to do this</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>((70000, 784), (70000, 10))
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="train-test-splits">
<h3>Train-test splits<a class="headerlink" href="#train-test-splits" title="Permalink to this headline">¶</a></h3>
<p>Usually, simple hold-outs are used. This is valid if the datasets are large enough, and you take into account the usual concerns, such as stratification and grouping. For smaller datasets, you can use cross-validation as well, but you may get high variance in the per-fold results as neural networks may not always converge.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># For Fashion MNIST, there exists a predefined stratified train-test split of 60000-10000. We therefore don&#39;t shuffle or stratify here.</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mi">60000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can further split the training set into a training and validation set</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Xf_train</span><span class="p">,</span> <span class="n">x_val</span><span class="p">,</span> <span class="n">yf_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="building-sequential-networks">
<h3>Building Sequential networks<a class="headerlink" href="#building-sequential-networks" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/Sequential">Sequential</a> models are the simplest kind of neural nets. They consist of a series of layers, one after the other.</p></li>
<li><p>There exist <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers">many types of layers</a></p></li>
<li><p>For now, we’ll only use <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense">Dense</a> (fully-connected) layers. It has several important settings:</p>
<ul>
<li><p>units: the number of nodes</p></li>
<li><p>activation: the <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/activations">activation function</a> to use</p></li>
<li><p>kernel_initializer: how to <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers">initialize the weights</a></p></li>
<li><p>kernel_regularizer: whether to apply L1/L2 <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/regularizers">regularization</a></p></li>
</ul>
</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span>
    <span class="n">units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span>
    <span class="n">bias_initializer</span><span class="o">=</span><span class="s1">&#39;zeros&#39;</span><span class="p">,</span> <span class="n">kernel_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">activity_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">kernel_constraint</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias_constraint</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</pre></div>
</div>
<p>A simple network with one hidden layer looks like this:</p>
<ul class="simple">
<li><p>Sequential.add() adds a layer to the network</p></li>
<li><p>You can also pass an array of layers to the constructor: ‘Sequential([layers])’</p></li>
<li><p>We use ReLU activation for the hidden layer and SoftMax for the output layer.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">models</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Metal device set to: Apple M1 Pro
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-02-16 13:11:55.821931: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.
2022-02-16 13:11:55.822626: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -&gt; physical PluggableDevice (device: 0, name: METAL, pci bus id: &lt;undefined&gt;)
</pre></div>
</div>
</div>
</div>
<div class="section" id="the-input-layer">
<h4>The input layer<a class="headerlink" href="#the-input-layer" title="Permalink to this headline">¶</a></h4>
<p>Note that the input layer can be defined by ‘input_shape’. Alternatively, you could also add an explicit input layer.
In this case, the data is a flattened array of 28*28 inputs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">InputLayer</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="activation-layers">
<h4>Activation layers<a class="headerlink" href="#activation-layers" title="Permalink to this headline">¶</a></h4>
<p>You can specify most activation functions, initializers, and regularizers as keyword strings.
If you need more control, you can specify the activation as an activation layer. The Dense layer will then use a linear activation, and the next layers applied your preferred activation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">InputLayer</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">negative_slope</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span> <span class="c1"># A leaky ReLU</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="model-summary">
<h4>Model summary<a class="headerlink" href="#model-summary" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>‘model.summary()’ prints a layer-wise summary of the model</p>
<ul>
<li><p>hidden layer 1 : (28 * 28 + 1) * 512 = 401920</p></li>
<li><p>hidden layer 2 : (512 + 1) * 512 = 262656</p></li>
<li><p>output layer: (512 + 1) * 10 = 5130</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Add one more hidden layer for better performance</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;sequential_3&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_6 (Dense)             (None, 512)               401920    
                                                                 
 dense_7 (Dense)             (None, 512)               262656    
                                                                 
 dense_8 (Dense)             (None, 10)                5130      
                                                                 
=================================================================
Total params: 669,706
Trainable params: 669,706
Non-trainable params: 0
_________________________________________________________________
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="choosing-loss-optimizer-metrics">
<h3>Choosing loss, optimizer, metrics<a class="headerlink" href="#choosing-loss-optimizer-metrics" title="Permalink to this headline">¶</a></h3>
<p>‘model.compile()’ specifies how the model should be trained, i.e. which loss function and optimizer to use and which evaluation metrics to report.</p>
<ul class="simple">
<li><p><strong>Loss function</strong> <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/losses">See overview</a></p>
<ul>
<li><p>Cross-entropy (log loss) for multi-class classification (<span class="math notranslate nohighlight">\(y_{true}\)</span> is one-hot encoded)</p></li>
<li><p>Use binary crossentropy for binary problems (single output node)</p></li>
<li><p>Use sparse categorical crossentropy if <span class="math notranslate nohighlight">\(y_{true}\)</span> is label-encoded (1,2,3,…)</p></li>
</ul>
</li>
<li><p><strong>Optimizer</strong> <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers">See overview</a></p>
<ul>
<li><p>Any of the available optimizers. RMSprop usually works well.</p></li>
</ul>
</li>
<li><p><strong>Metrics</strong> <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/metrics">See overview</a></p>
<ul>
<li><p>To monitor performance during training and testing, e.g. accuracy</p></li>
</ul>
</li>
</ul>
<p>The defaults versions of all of these can be specified by keywords</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Shorthand</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>For more control, the actual functions can be passed.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">RMSprop</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.losses</span> <span class="kn">import</span> <span class="n">CategoricalCrossentropy</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.metrics</span> <span class="kn">import</span> <span class="n">Accuracy</span>

<span class="c1"># Detailed</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">CategoricalCrossentropy</span><span class="p">(</span><span class="n">label_smoothing</span><span class="o">=</span><span class="mf">0.01</span><span class="p">),</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="n">RMSprop</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.0</span><span class="p">),</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">Accuracy</span><span class="p">()])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="training-fitting">
<h3>Training (fitting)<a class="headerlink" href="#training-fitting" title="Permalink to this headline">¶</a></h3>
<p>The ‘fit’ function trains the network and returns a history of the training and validation loss and all metrics per epoch.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">network</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
</pre></div>
</div>
<p>There are 2 important hyperparameters:</p>
<ul class="simple">
<li><p>Number of epochs: enough to allow convergence</p>
<ul>
<li><p>Too much: model starts overfitting (or just wastes time)</p></li>
</ul>
</li>
<li><p>Batch size: small batches (e.g. 32, 64,… samples) often preferred</p>
<ul>
<li><p>‘Noisy’ training data makes overfitting less likely</p>
<ul>
<li><p>Larger batches generalize less well (‘generalization gap’)</p></li>
</ul>
</li>
<li><p>Requires less memory (especially in GPUs)</p></li>
<li><p>Large batches do speed up training, may converge in fewer epochs</p></li>
</ul>
</li>
</ul>
<div class="section" id="repeated-fitting">
<h4>Repeated fitting<a class="headerlink" href="#repeated-fitting" title="Permalink to this headline">¶</a></h4>
<p>Calling ‘model.fit’ multiple times does not recreate the model from scratch (like scikit-learn does), it just continues training with the stored weights. To train from scratch, e.g. with different hyperparameters, you need to recreate the model, e.g. by wrapping it as a create_model function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_model</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_normal&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_normal&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="tracking-progress">
<h4>Tracking progress<a class="headerlink" href="#tracking-progress" title="Permalink to this headline">¶</a></h4>
<p>Calling ‘fit’ will print out the progress for every epoch, and returns a ‘history’ object which all losses and evaluation metrics.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">()</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xf_train</span><span class="p">,</span> <span class="n">yf_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/3
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-02-16 13:11:56.094484: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz
2022-02-16 13:11:56.249616: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/782 [..............................] - ETA: 3:39 - loss: 2.2452 - accuracy: 0.1250
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
  8/782 [..............................] - ETA: 6s - loss: 2.0674 - accuracy: 0.4102  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 15/782 [..............................] - ETA: 6s - loss: 1.5714 - accuracy: 0.5094
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 21/782 [..............................] - ETA: 6s - loss: 1.3762 - accuracy: 0.5603
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 28/782 [&gt;.............................] - ETA: 6s - loss: 1.2763 - accuracy: 0.5765
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 35/782 [&gt;.............................] - ETA: 5s - loss: 1.1829 - accuracy: 0.6009
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 42/782 [&gt;.............................] - ETA: 5s - loss: 1.1262 - accuracy: 0.6176
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 49/782 [&gt;.............................] - ETA: 5s - loss: 1.0673 - accuracy: 0.6349
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 55/782 [=&gt;............................] - ETA: 5s - loss: 1.0353 - accuracy: 0.6426
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 61/782 [=&gt;............................] - ETA: 5s - loss: 1.0012 - accuracy: 0.6519
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 67/782 [=&gt;............................] - ETA: 5s - loss: 0.9723 - accuracy: 0.6602
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 74/782 [=&gt;............................] - ETA: 5s - loss: 0.9409 - accuracy: 0.6704
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 79/782 [==&gt;...........................] - ETA: 5s - loss: 0.9228 - accuracy: 0.6754
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 84/782 [==&gt;...........................] - ETA: 5s - loss: 0.9067 - accuracy: 0.6801
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 91/782 [==&gt;...........................] - ETA: 5s - loss: 0.8927 - accuracy: 0.6832
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 98/782 [==&gt;...........................] - ETA: 5s - loss: 0.8653 - accuracy: 0.6921
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
105/782 [===&gt;..........................] - ETA: 5s - loss: 0.8454 - accuracy: 0.6976
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
112/782 [===&gt;..........................] - ETA: 5s - loss: 0.8348 - accuracy: 0.7002
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
119/782 [===&gt;..........................] - ETA: 5s - loss: 0.8187 - accuracy: 0.7068
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
126/782 [===&gt;..........................] - ETA: 5s - loss: 0.8043 - accuracy: 0.7109
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
133/782 [====&gt;.........................] - ETA: 5s - loss: 0.7930 - accuracy: 0.7142
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
140/782 [====&gt;.........................] - ETA: 5s - loss: 0.7826 - accuracy: 0.7176
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
147/782 [====&gt;.........................] - ETA: 5s - loss: 0.7728 - accuracy: 0.7211
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
154/782 [====&gt;.........................] - ETA: 5s - loss: 0.7688 - accuracy: 0.7226
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
161/782 [=====&gt;........................] - ETA: 4s - loss: 0.7569 - accuracy: 0.7270
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
168/782 [=====&gt;........................] - ETA: 4s - loss: 0.7473 - accuracy: 0.7304
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
175/782 [=====&gt;........................] - ETA: 4s - loss: 0.7419 - accuracy: 0.7324
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
182/782 [=====&gt;........................] - ETA: 4s - loss: 0.7348 - accuracy: 0.7351
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
189/782 [======&gt;.......................] - ETA: 4s - loss: 0.7315 - accuracy: 0.7358
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
196/782 [======&gt;.......................] - ETA: 4s - loss: 0.7263 - accuracy: 0.7377
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
203/782 [======&gt;.......................] - ETA: 4s - loss: 0.7209 - accuracy: 0.7395
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
210/782 [=======&gt;......................] - ETA: 4s - loss: 0.7128 - accuracy: 0.7420
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
217/782 [=======&gt;......................] - ETA: 4s - loss: 0.7063 - accuracy: 0.7447
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
224/782 [=======&gt;......................] - ETA: 4s - loss: 0.6987 - accuracy: 0.7476
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
231/782 [=======&gt;......................] - ETA: 4s - loss: 0.6933 - accuracy: 0.7495
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
238/782 [========&gt;.....................] - ETA: 4s - loss: 0.6889 - accuracy: 0.7508
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
245/782 [========&gt;.....................] - ETA: 4s - loss: 0.6851 - accuracy: 0.7517
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
252/782 [========&gt;.....................] - ETA: 4s - loss: 0.6815 - accuracy: 0.7526
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
259/782 [========&gt;.....................] - ETA: 4s - loss: 0.6774 - accuracy: 0.7536
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
266/782 [=========&gt;....................] - ETA: 4s - loss: 0.6722 - accuracy: 0.7548
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
273/782 [=========&gt;....................] - ETA: 3s - loss: 0.6683 - accuracy: 0.7559
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
280/782 [=========&gt;....................] - ETA: 3s - loss: 0.6630 - accuracy: 0.7580
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
287/782 [==========&gt;...................] - ETA: 3s - loss: 0.6586 - accuracy: 0.7597
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
294/782 [==========&gt;...................] - ETA: 3s - loss: 0.6543 - accuracy: 0.7611
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
301/782 [==========&gt;...................] - ETA: 3s - loss: 0.6507 - accuracy: 0.7624
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
308/782 [==========&gt;...................] - ETA: 3s - loss: 0.6475 - accuracy: 0.7636
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
315/782 [===========&gt;..................] - ETA: 3s - loss: 0.6418 - accuracy: 0.7655
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
322/782 [===========&gt;..................] - ETA: 3s - loss: 0.6381 - accuracy: 0.7667
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
329/782 [===========&gt;..................] - ETA: 3s - loss: 0.6350 - accuracy: 0.7679
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
336/782 [===========&gt;..................] - ETA: 3s - loss: 0.6308 - accuracy: 0.7695
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
343/782 [============&gt;.................] - ETA: 3s - loss: 0.6293 - accuracy: 0.7700
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
350/782 [============&gt;.................] - ETA: 3s - loss: 0.6248 - accuracy: 0.7715
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
357/782 [============&gt;.................] - ETA: 3s - loss: 0.6220 - accuracy: 0.7727
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
364/782 [============&gt;.................] - ETA: 3s - loss: 0.6181 - accuracy: 0.7740
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
371/782 [=============&gt;................] - ETA: 3s - loss: 0.6147 - accuracy: 0.7751
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
378/782 [=============&gt;................] - ETA: 3s - loss: 0.6137 - accuracy: 0.7753
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
384/782 [=============&gt;................] - ETA: 3s - loss: 0.6113 - accuracy: 0.7761
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
391/782 [==============&gt;...............] - ETA: 3s - loss: 0.6090 - accuracy: 0.7769
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
398/782 [==============&gt;...............] - ETA: 2s - loss: 0.6052 - accuracy: 0.7783
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
405/782 [==============&gt;...............] - ETA: 2s - loss: 0.6035 - accuracy: 0.7793
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
412/782 [==============&gt;...............] - ETA: 2s - loss: 0.6004 - accuracy: 0.7803
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
419/782 [===============&gt;..............] - ETA: 2s - loss: 0.5984 - accuracy: 0.7809
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
426/782 [===============&gt;..............] - ETA: 2s - loss: 0.5972 - accuracy: 0.7814
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
433/782 [===============&gt;..............] - ETA: 2s - loss: 0.5948 - accuracy: 0.7824
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
440/782 [===============&gt;..............] - ETA: 2s - loss: 0.5918 - accuracy: 0.7832
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
447/782 [================&gt;.............] - ETA: 2s - loss: 0.5896 - accuracy: 0.7841
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
453/782 [================&gt;.............] - ETA: 2s - loss: 0.5887 - accuracy: 0.7844
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
460/782 [================&gt;.............] - ETA: 2s - loss: 0.5877 - accuracy: 0.7846
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
467/782 [================&gt;.............] - ETA: 2s - loss: 0.5850 - accuracy: 0.7853
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
474/782 [=================&gt;............] - ETA: 2s - loss: 0.5826 - accuracy: 0.7863
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
481/782 [=================&gt;............] - ETA: 2s - loss: 0.5806 - accuracy: 0.7874
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
488/782 [=================&gt;............] - ETA: 2s - loss: 0.5785 - accuracy: 0.7883
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
495/782 [=================&gt;............] - ETA: 2s - loss: 0.5768 - accuracy: 0.7887
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
502/782 [==================&gt;...........] - ETA: 2s - loss: 0.5749 - accuracy: 0.7893
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
509/782 [==================&gt;...........] - ETA: 2s - loss: 0.5743 - accuracy: 0.7894
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
516/782 [==================&gt;...........] - ETA: 2s - loss: 0.5731 - accuracy: 0.7901
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
523/782 [===================&gt;..........] - ETA: 1s - loss: 0.5709 - accuracy: 0.7909
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
530/782 [===================&gt;..........] - ETA: 1s - loss: 0.5689 - accuracy: 0.7915
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
537/782 [===================&gt;..........] - ETA: 1s - loss: 0.5674 - accuracy: 0.7918
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
544/782 [===================&gt;..........] - ETA: 1s - loss: 0.5654 - accuracy: 0.7927
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
551/782 [====================&gt;.........] - ETA: 1s - loss: 0.5638 - accuracy: 0.7932
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
558/782 [====================&gt;.........] - ETA: 1s - loss: 0.5622 - accuracy: 0.7940
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
564/782 [====================&gt;.........] - ETA: 1s - loss: 0.5604 - accuracy: 0.7947
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
571/782 [====================&gt;.........] - ETA: 1s - loss: 0.5597 - accuracy: 0.7950
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
578/782 [=====================&gt;........] - ETA: 1s - loss: 0.5576 - accuracy: 0.7957
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
585/782 [=====================&gt;........] - ETA: 1s - loss: 0.5562 - accuracy: 0.7964
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
592/782 [=====================&gt;........] - ETA: 1s - loss: 0.5544 - accuracy: 0.7973
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
599/782 [=====================&gt;........] - ETA: 1s - loss: 0.5532 - accuracy: 0.7978
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
606/782 [======================&gt;.......] - ETA: 1s - loss: 0.5529 - accuracy: 0.7978
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
613/782 [======================&gt;.......] - ETA: 1s - loss: 0.5507 - accuracy: 0.7985
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
620/782 [======================&gt;.......] - ETA: 1s - loss: 0.5501 - accuracy: 0.7988
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
627/782 [=======================&gt;......] - ETA: 1s - loss: 0.5490 - accuracy: 0.7991
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
634/782 [=======================&gt;......] - ETA: 1s - loss: 0.5481 - accuracy: 0.7992
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
641/782 [=======================&gt;......] - ETA: 1s - loss: 0.5467 - accuracy: 0.7997
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
648/782 [=======================&gt;......] - ETA: 1s - loss: 0.5450 - accuracy: 0.8002
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
655/782 [========================&gt;.....] - ETA: 0s - loss: 0.5436 - accuracy: 0.8007
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
662/782 [========================&gt;.....] - ETA: 0s - loss: 0.5424 - accuracy: 0.8010
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
669/782 [========================&gt;.....] - ETA: 0s - loss: 0.5421 - accuracy: 0.8013
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
676/782 [========================&gt;.....] - ETA: 0s - loss: 0.5402 - accuracy: 0.8021
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
683/782 [=========================&gt;....] - ETA: 0s - loss: 0.5390 - accuracy: 0.8023
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
690/782 [=========================&gt;....] - ETA: 0s - loss: 0.5374 - accuracy: 0.8030
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
697/782 [=========================&gt;....] - ETA: 0s - loss: 0.5359 - accuracy: 0.8035
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
704/782 [==========================&gt;...] - ETA: 0s - loss: 0.5350 - accuracy: 0.8038
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
711/782 [==========================&gt;...] - ETA: 0s - loss: 0.5335 - accuracy: 0.8043
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
717/782 [==========================&gt;...] - ETA: 0s - loss: 0.5320 - accuracy: 0.8051
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
724/782 [==========================&gt;...] - ETA: 0s - loss: 0.5308 - accuracy: 0.8055
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
731/782 [===========================&gt;..] - ETA: 0s - loss: 0.5298 - accuracy: 0.8060
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
738/782 [===========================&gt;..] - ETA: 0s - loss: 0.5287 - accuracy: 0.8064
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
746/782 [===========================&gt;..] - ETA: 0s - loss: 0.5275 - accuracy: 0.8071
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
753/782 [===========================&gt;..] - ETA: 0s - loss: 0.5272 - accuracy: 0.8071
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
760/782 [============================&gt;.] - ETA: 0s - loss: 0.5259 - accuracy: 0.8076
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
767/782 [============================&gt;.] - ETA: 0s - loss: 0.5241 - accuracy: 0.8083
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
774/782 [============================&gt;.] - ETA: 0s - loss: 0.5232 - accuracy: 0.8087
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
781/782 [============================&gt;.] - ETA: 0s - loss: 0.5227 - accuracy: 0.8090
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
782/782 [==============================] - 6s 8ms/step - loss: 0.5226 - accuracy: 0.8090
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2/3

  1/782 [..............................] - ETA: 5s - loss: 0.4950 - accuracy: 0.8281
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
  8/782 [..............................] - ETA: 5s - loss: 0.3540 - accuracy: 0.8789
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 15/782 [..............................] - ETA: 5s - loss: 0.3776 - accuracy: 0.8583
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 22/782 [..............................] - ETA: 5s - loss: 0.3813 - accuracy: 0.8558
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 29/782 [&gt;.............................] - ETA: 5s - loss: 0.3963 - accuracy: 0.8491
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 36/782 [&gt;.............................] - ETA: 5s - loss: 0.3810 - accuracy: 0.8516
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 44/782 [&gt;.............................] - ETA: 5s - loss: 0.3889 - accuracy: 0.8501
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 51/782 [&gt;.............................] - ETA: 5s - loss: 0.3898 - accuracy: 0.8523
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 58/782 [=&gt;............................] - ETA: 5s - loss: 0.3983 - accuracy: 0.8489
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 65/782 [=&gt;............................] - ETA: 5s - loss: 0.3991 - accuracy: 0.8478
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 72/782 [=&gt;............................] - ETA: 5s - loss: 0.3953 - accuracy: 0.8511
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 79/782 [==&gt;...........................] - ETA: 5s - loss: 0.3967 - accuracy: 0.8509
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 86/782 [==&gt;...........................] - ETA: 5s - loss: 0.3973 - accuracy: 0.8505
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 93/782 [==&gt;...........................] - ETA: 5s - loss: 0.3961 - accuracy: 0.8510
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
100/782 [==&gt;...........................] - ETA: 5s - loss: 0.3950 - accuracy: 0.8516
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
107/782 [===&gt;..........................] - ETA: 5s - loss: 0.4000 - accuracy: 0.8506
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
114/782 [===&gt;..........................] - ETA: 4s - loss: 0.3945 - accuracy: 0.8524
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
121/782 [===&gt;..........................] - ETA: 4s - loss: 0.3907 - accuracy: 0.8538
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
128/782 [===&gt;..........................] - ETA: 4s - loss: 0.3939 - accuracy: 0.8534
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
134/782 [====&gt;.........................] - ETA: 4s - loss: 0.3911 - accuracy: 0.8539
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
141/782 [====&gt;.........................] - ETA: 4s - loss: 0.3948 - accuracy: 0.8524
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
148/782 [====&gt;.........................] - ETA: 4s - loss: 0.3935 - accuracy: 0.8528
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
155/782 [====&gt;.........................] - ETA: 4s - loss: 0.3918 - accuracy: 0.8536
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
162/782 [=====&gt;........................] - ETA: 4s - loss: 0.3921 - accuracy: 0.8535
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
169/782 [=====&gt;........................] - ETA: 4s - loss: 0.3924 - accuracy: 0.8536
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
176/782 [=====&gt;........................] - ETA: 4s - loss: 0.3912 - accuracy: 0.8535
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
183/782 [======&gt;.......................] - ETA: 4s - loss: 0.3908 - accuracy: 0.8541
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
189/782 [======&gt;.......................] - ETA: 4s - loss: 0.3908 - accuracy: 0.8543
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
196/782 [======&gt;.......................] - ETA: 4s - loss: 0.3906 - accuracy: 0.8548
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
203/782 [======&gt;.......................] - ETA: 4s - loss: 0.3890 - accuracy: 0.8551
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
210/782 [=======&gt;......................] - ETA: 4s - loss: 0.3899 - accuracy: 0.8550
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
217/782 [=======&gt;......................] - ETA: 4s - loss: 0.3892 - accuracy: 0.8556
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
224/782 [=======&gt;......................] - ETA: 4s - loss: 0.3889 - accuracy: 0.8560
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
231/782 [=======&gt;......................] - ETA: 4s - loss: 0.3883 - accuracy: 0.8563
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
238/782 [========&gt;.....................] - ETA: 4s - loss: 0.3884 - accuracy: 0.8571
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
245/782 [========&gt;.....................] - ETA: 4s - loss: 0.3898 - accuracy: 0.8570
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
252/782 [========&gt;.....................] - ETA: 3s - loss: 0.3910 - accuracy: 0.8562
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
259/782 [========&gt;.....................] - ETA: 3s - loss: 0.3918 - accuracy: 0.8559
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
266/782 [=========&gt;....................] - ETA: 3s - loss: 0.3925 - accuracy: 0.8558
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
273/782 [=========&gt;....................] - ETA: 3s - loss: 0.3918 - accuracy: 0.8565
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
280/782 [=========&gt;....................] - ETA: 3s - loss: 0.3909 - accuracy: 0.8569
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
287/782 [==========&gt;...................] - ETA: 3s - loss: 0.3908 - accuracy: 0.8573
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
294/782 [==========&gt;...................] - ETA: 3s - loss: 0.3900 - accuracy: 0.8573
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
301/782 [==========&gt;...................] - ETA: 3s - loss: 0.3910 - accuracy: 0.8572
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
308/782 [==========&gt;...................] - ETA: 3s - loss: 0.3916 - accuracy: 0.8568
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
315/782 [===========&gt;..................] - ETA: 3s - loss: 0.3911 - accuracy: 0.8569
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
322/782 [===========&gt;..................] - ETA: 3s - loss: 0.3927 - accuracy: 0.8566
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
328/782 [===========&gt;..................] - ETA: 3s - loss: 0.3920 - accuracy: 0.8569
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
335/782 [===========&gt;..................] - ETA: 3s - loss: 0.3919 - accuracy: 0.8574
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
342/782 [============&gt;.................] - ETA: 3s - loss: 0.3920 - accuracy: 0.8574
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
349/782 [============&gt;.................] - ETA: 3s - loss: 0.3914 - accuracy: 0.8575
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
356/782 [============&gt;.................] - ETA: 3s - loss: 0.3916 - accuracy: 0.8575
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
363/782 [============&gt;.................] - ETA: 3s - loss: 0.3918 - accuracy: 0.8573
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
370/782 [=============&gt;................] - ETA: 3s - loss: 0.3917 - accuracy: 0.8572
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
377/782 [=============&gt;................] - ETA: 3s - loss: 0.3911 - accuracy: 0.8574
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
384/782 [=============&gt;................] - ETA: 2s - loss: 0.3915 - accuracy: 0.8571
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
391/782 [==============&gt;...............] - ETA: 2s - loss: 0.3905 - accuracy: 0.8574
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
397/782 [==============&gt;...............] - ETA: 2s - loss: 0.3903 - accuracy: 0.8571
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
404/782 [==============&gt;...............] - ETA: 2s - loss: 0.3906 - accuracy: 0.8568
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
411/782 [==============&gt;...............] - ETA: 2s - loss: 0.3899 - accuracy: 0.8571
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
418/782 [===============&gt;..............] - ETA: 2s - loss: 0.3906 - accuracy: 0.8568
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
425/782 [===============&gt;..............] - ETA: 2s - loss: 0.3901 - accuracy: 0.8571
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
432/782 [===============&gt;..............] - ETA: 2s - loss: 0.3906 - accuracy: 0.8571
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
439/782 [===============&gt;..............] - ETA: 2s - loss: 0.3901 - accuracy: 0.8576
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
446/782 [================&gt;.............] - ETA: 2s - loss: 0.3905 - accuracy: 0.8577
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
453/782 [================&gt;.............] - ETA: 2s - loss: 0.3906 - accuracy: 0.8577
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
460/782 [================&gt;.............] - ETA: 2s - loss: 0.3902 - accuracy: 0.8578
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
467/782 [================&gt;.............] - ETA: 2s - loss: 0.3912 - accuracy: 0.8574
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
474/782 [=================&gt;............] - ETA: 2s - loss: 0.3912 - accuracy: 0.8571
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
481/782 [=================&gt;............] - ETA: 2s - loss: 0.3914 - accuracy: 0.8572
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
488/782 [=================&gt;............] - ETA: 2s - loss: 0.3914 - accuracy: 0.8573
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
495/782 [=================&gt;............] - ETA: 2s - loss: 0.3919 - accuracy: 0.8576
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
502/782 [==================&gt;...........] - ETA: 2s - loss: 0.3904 - accuracy: 0.8582
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
509/782 [==================&gt;...........] - ETA: 2s - loss: 0.3909 - accuracy: 0.8579
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
516/782 [==================&gt;...........] - ETA: 1s - loss: 0.3909 - accuracy: 0.8578
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
523/782 [===================&gt;..........] - ETA: 1s - loss: 0.3903 - accuracy: 0.8581
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
530/782 [===================&gt;..........] - ETA: 1s - loss: 0.3896 - accuracy: 0.8580
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
537/782 [===================&gt;..........] - ETA: 1s - loss: 0.3890 - accuracy: 0.8584
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
544/782 [===================&gt;..........] - ETA: 1s - loss: 0.3894 - accuracy: 0.8583
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
551/782 [====================&gt;.........] - ETA: 1s - loss: 0.3897 - accuracy: 0.8583
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
558/782 [====================&gt;.........] - ETA: 1s - loss: 0.3896 - accuracy: 0.8581
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
565/782 [====================&gt;.........] - ETA: 1s - loss: 0.3904 - accuracy: 0.8579
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
572/782 [====================&gt;.........] - ETA: 1s - loss: 0.3900 - accuracy: 0.8579
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
579/782 [=====================&gt;........] - ETA: 1s - loss: 0.3893 - accuracy: 0.8582
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
586/782 [=====================&gt;........] - ETA: 1s - loss: 0.3889 - accuracy: 0.8582
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
593/782 [=====================&gt;........] - ETA: 1s - loss: 0.3893 - accuracy: 0.8580
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
600/782 [======================&gt;.......] - ETA: 1s - loss: 0.3898 - accuracy: 0.8575
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
607/782 [======================&gt;.......] - ETA: 1s - loss: 0.3890 - accuracy: 0.8576
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
614/782 [======================&gt;.......] - ETA: 1s - loss: 0.3893 - accuracy: 0.8573
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
621/782 [======================&gt;.......] - ETA: 1s - loss: 0.3894 - accuracy: 0.8575
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
628/782 [=======================&gt;......] - ETA: 1s - loss: 0.3895 - accuracy: 0.8573
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
635/782 [=======================&gt;......] - ETA: 1s - loss: 0.3890 - accuracy: 0.8574
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
642/782 [=======================&gt;......] - ETA: 1s - loss: 0.3896 - accuracy: 0.8572
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
649/782 [=======================&gt;......] - ETA: 0s - loss: 0.3894 - accuracy: 0.8573
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
656/782 [========================&gt;.....] - ETA: 0s - loss: 0.3893 - accuracy: 0.8574
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
663/782 [========================&gt;.....] - ETA: 0s - loss: 0.3891 - accuracy: 0.8572
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
670/782 [========================&gt;.....] - ETA: 0s - loss: 0.3893 - accuracy: 0.8571
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
677/782 [========================&gt;.....] - ETA: 0s - loss: 0.3895 - accuracy: 0.8570
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
684/782 [=========================&gt;....] - ETA: 0s - loss: 0.3890 - accuracy: 0.8573
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
691/782 [=========================&gt;....] - ETA: 0s - loss: 0.3883 - accuracy: 0.8576
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
698/782 [=========================&gt;....] - ETA: 0s - loss: 0.3882 - accuracy: 0.8578
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
705/782 [==========================&gt;...] - ETA: 0s - loss: 0.3883 - accuracy: 0.8578
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
712/782 [==========================&gt;...] - ETA: 0s - loss: 0.3889 - accuracy: 0.8576
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
719/782 [==========================&gt;...] - ETA: 0s - loss: 0.3891 - accuracy: 0.8574
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
726/782 [==========================&gt;...] - ETA: 0s - loss: 0.3891 - accuracy: 0.8576
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
733/782 [===========================&gt;..] - ETA: 0s - loss: 0.3888 - accuracy: 0.8576
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
740/782 [===========================&gt;..] - ETA: 0s - loss: 0.3876 - accuracy: 0.8581
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
747/782 [===========================&gt;..] - ETA: 0s - loss: 0.3880 - accuracy: 0.8581
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
754/782 [===========================&gt;..] - ETA: 0s - loss: 0.3875 - accuracy: 0.8583
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
761/782 [============================&gt;.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8586
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
768/782 [============================&gt;.] - ETA: 0s - loss: 0.3872 - accuracy: 0.8586
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
775/782 [============================&gt;.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8586
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
782/782 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.8588
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
782/782 [==============================] - 6s 8ms/step - loss: 0.3863 - accuracy: 0.8588
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3/3

  1/782 [..............................] - ETA: 5s - loss: 0.5861 - accuracy: 0.7969
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
  8/782 [..............................] - ETA: 5s - loss: 0.3651 - accuracy: 0.8691
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 15/782 [..............................] - ETA: 5s - loss: 0.3654 - accuracy: 0.8688
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 22/782 [..............................] - ETA: 5s - loss: 0.3491 - accuracy: 0.8714
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 29/782 [&gt;.............................] - ETA: 5s - loss: 0.3727 - accuracy: 0.8675
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 36/782 [&gt;.............................] - ETA: 5s - loss: 0.3787 - accuracy: 0.8633
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 43/782 [&gt;.............................] - ETA: 5s - loss: 0.3693 - accuracy: 0.8677
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 50/782 [&gt;.............................] - ETA: 5s - loss: 0.3655 - accuracy: 0.8691
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 57/782 [=&gt;............................] - ETA: 5s - loss: 0.3604 - accuracy: 0.8701
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 64/782 [=&gt;............................] - ETA: 5s - loss: 0.3623 - accuracy: 0.8682
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 71/782 [=&gt;............................] - ETA: 5s - loss: 0.3586 - accuracy: 0.8680
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 78/782 [=&gt;............................] - ETA: 5s - loss: 0.3611 - accuracy: 0.8674
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 85/782 [==&gt;...........................] - ETA: 5s - loss: 0.3604 - accuracy: 0.8667
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 92/782 [==&gt;...........................] - ETA: 5s - loss: 0.3597 - accuracy: 0.8663
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 99/782 [==&gt;...........................] - ETA: 5s - loss: 0.3646 - accuracy: 0.8636
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
106/782 [===&gt;..........................] - ETA: 5s - loss: 0.3617 - accuracy: 0.8644
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
113/782 [===&gt;..........................] - ETA: 5s - loss: 0.3605 - accuracy: 0.8652
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
120/782 [===&gt;..........................] - ETA: 4s - loss: 0.3592 - accuracy: 0.8664
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
127/782 [===&gt;..........................] - ETA: 4s - loss: 0.3606 - accuracy: 0.8670
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
134/782 [====&gt;.........................] - ETA: 4s - loss: 0.3613 - accuracy: 0.8671
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
141/782 [====&gt;.........................] - ETA: 4s - loss: 0.3581 - accuracy: 0.8672
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
148/782 [====&gt;.........................] - ETA: 4s - loss: 0.3587 - accuracy: 0.8675
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
155/782 [====&gt;.........................] - ETA: 4s - loss: 0.3580 - accuracy: 0.8679
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
162/782 [=====&gt;........................] - ETA: 4s - loss: 0.3593 - accuracy: 0.8682
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
169/782 [=====&gt;........................] - ETA: 4s - loss: 0.3590 - accuracy: 0.8676
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
176/782 [=====&gt;........................] - ETA: 4s - loss: 0.3611 - accuracy: 0.8671
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
183/782 [======&gt;.......................] - ETA: 4s - loss: 0.3623 - accuracy: 0.8673
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
190/782 [======&gt;.......................] - ETA: 4s - loss: 0.3613 - accuracy: 0.8676
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
197/782 [======&gt;.......................] - ETA: 4s - loss: 0.3620 - accuracy: 0.8672
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
204/782 [======&gt;.......................] - ETA: 4s - loss: 0.3606 - accuracy: 0.8671
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
211/782 [=======&gt;......................] - ETA: 4s - loss: 0.3610 - accuracy: 0.8674
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
218/782 [=======&gt;......................] - ETA: 4s - loss: 0.3604 - accuracy: 0.8678
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
225/782 [=======&gt;......................] - ETA: 4s - loss: 0.3601 - accuracy: 0.8687
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
232/782 [=======&gt;......................] - ETA: 4s - loss: 0.3584 - accuracy: 0.8693
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
239/782 [========&gt;.....................] - ETA: 4s - loss: 0.3575 - accuracy: 0.8695
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
246/782 [========&gt;.....................] - ETA: 3s - loss: 0.3576 - accuracy: 0.8689
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
253/782 [========&gt;.....................] - ETA: 3s - loss: 0.3560 - accuracy: 0.8695
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
260/782 [========&gt;.....................] - ETA: 3s - loss: 0.3550 - accuracy: 0.8702
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
267/782 [=========&gt;....................] - ETA: 3s - loss: 0.3553 - accuracy: 0.8704
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
274/782 [=========&gt;....................] - ETA: 3s - loss: 0.3561 - accuracy: 0.8712
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
281/782 [=========&gt;....................] - ETA: 3s - loss: 0.3582 - accuracy: 0.8706
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
288/782 [==========&gt;...................] - ETA: 3s - loss: 0.3587 - accuracy: 0.8707
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
295/782 [==========&gt;...................] - ETA: 3s - loss: 0.3577 - accuracy: 0.8713
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
302/782 [==========&gt;...................] - ETA: 3s - loss: 0.3577 - accuracy: 0.8715
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
309/782 [==========&gt;...................] - ETA: 3s - loss: 0.3579 - accuracy: 0.8709
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
316/782 [===========&gt;..................] - ETA: 3s - loss: 0.3581 - accuracy: 0.8708
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
323/782 [===========&gt;..................] - ETA: 3s - loss: 0.3574 - accuracy: 0.8710
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
330/782 [===========&gt;..................] - ETA: 3s - loss: 0.3570 - accuracy: 0.8709
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
337/782 [===========&gt;..................] - ETA: 3s - loss: 0.3568 - accuracy: 0.8712
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
344/782 [============&gt;.................] - ETA: 3s - loss: 0.3573 - accuracy: 0.8710
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
351/782 [============&gt;.................] - ETA: 3s - loss: 0.3569 - accuracy: 0.8710
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
358/782 [============&gt;.................] - ETA: 3s - loss: 0.3568 - accuracy: 0.8708
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
365/782 [=============&gt;................] - ETA: 3s - loss: 0.3564 - accuracy: 0.8706
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
372/782 [=============&gt;................] - ETA: 3s - loss: 0.3566 - accuracy: 0.8706
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
379/782 [=============&gt;................] - ETA: 3s - loss: 0.3568 - accuracy: 0.8706
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
386/782 [=============&gt;................] - ETA: 2s - loss: 0.3575 - accuracy: 0.8705
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
393/782 [==============&gt;...............] - ETA: 2s - loss: 0.3587 - accuracy: 0.8699
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
400/782 [==============&gt;...............] - ETA: 2s - loss: 0.3584 - accuracy: 0.8703
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
407/782 [==============&gt;...............] - ETA: 2s - loss: 0.3600 - accuracy: 0.8696
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
414/782 [==============&gt;...............] - ETA: 2s - loss: 0.3598 - accuracy: 0.8698
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
421/782 [===============&gt;..............] - ETA: 2s - loss: 0.3588 - accuracy: 0.8701
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
428/782 [===============&gt;..............] - ETA: 2s - loss: 0.3589 - accuracy: 0.8700
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
435/782 [===============&gt;..............] - ETA: 2s - loss: 0.3590 - accuracy: 0.8698
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
443/782 [===============&gt;..............] - ETA: 2s - loss: 0.3587 - accuracy: 0.8698
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
450/782 [================&gt;.............] - ETA: 2s - loss: 0.3585 - accuracy: 0.8700
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
457/782 [================&gt;.............] - ETA: 2s - loss: 0.3576 - accuracy: 0.8705
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
464/782 [================&gt;.............] - ETA: 2s - loss: 0.3569 - accuracy: 0.8706
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
471/782 [=================&gt;............] - ETA: 2s - loss: 0.3573 - accuracy: 0.8706
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
478/782 [=================&gt;............] - ETA: 2s - loss: 0.3566 - accuracy: 0.8709
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
485/782 [=================&gt;............] - ETA: 2s - loss: 0.3562 - accuracy: 0.8709
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
492/782 [=================&gt;............] - ETA: 2s - loss: 0.3561 - accuracy: 0.8710
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
499/782 [==================&gt;...........] - ETA: 2s - loss: 0.3562 - accuracy: 0.8711
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
506/782 [==================&gt;...........] - ETA: 2s - loss: 0.3564 - accuracy: 0.8710
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
513/782 [==================&gt;...........] - ETA: 2s - loss: 0.3565 - accuracy: 0.8710
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
520/782 [==================&gt;...........] - ETA: 1s - loss: 0.3555 - accuracy: 0.8713
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
527/782 [===================&gt;..........] - ETA: 1s - loss: 0.3558 - accuracy: 0.8714
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
534/782 [===================&gt;..........] - ETA: 1s - loss: 0.3557 - accuracy: 0.8715
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
541/782 [===================&gt;..........] - ETA: 1s - loss: 0.3561 - accuracy: 0.8710
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
548/782 [====================&gt;.........] - ETA: 1s - loss: 0.3567 - accuracy: 0.8709
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
555/782 [====================&gt;.........] - ETA: 1s - loss: 0.3566 - accuracy: 0.8709
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
562/782 [====================&gt;.........] - ETA: 1s - loss: 0.3565 - accuracy: 0.8711
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
569/782 [====================&gt;.........] - ETA: 1s - loss: 0.3568 - accuracy: 0.8707
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
576/782 [=====================&gt;........] - ETA: 1s - loss: 0.3575 - accuracy: 0.8705
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
581/782 [=====================&gt;........] - ETA: 1s - loss: 0.3571 - accuracy: 0.8706
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
588/782 [=====================&gt;........] - ETA: 1s - loss: 0.3567 - accuracy: 0.8705
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
595/782 [=====================&gt;........] - ETA: 1s - loss: 0.3571 - accuracy: 0.8702
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
602/782 [======================&gt;.......] - ETA: 1s - loss: 0.3574 - accuracy: 0.8700
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
609/782 [======================&gt;.......] - ETA: 1s - loss: 0.3573 - accuracy: 0.8700
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
616/782 [======================&gt;.......] - ETA: 1s - loss: 0.3580 - accuracy: 0.8699
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
623/782 [======================&gt;.......] - ETA: 1s - loss: 0.3577 - accuracy: 0.8700
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
630/782 [=======================&gt;......] - ETA: 1s - loss: 0.3573 - accuracy: 0.8700
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
637/782 [=======================&gt;......] - ETA: 1s - loss: 0.3575 - accuracy: 0.8701
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
644/782 [=======================&gt;......] - ETA: 1s - loss: 0.3577 - accuracy: 0.8701
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
651/782 [=======================&gt;......] - ETA: 0s - loss: 0.3578 - accuracy: 0.8700
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
658/782 [========================&gt;.....] - ETA: 0s - loss: 0.3577 - accuracy: 0.8700
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
665/782 [========================&gt;.....] - ETA: 0s - loss: 0.3572 - accuracy: 0.8699
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
672/782 [========================&gt;.....] - ETA: 0s - loss: 0.3563 - accuracy: 0.8703
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
679/782 [=========================&gt;....] - ETA: 0s - loss: 0.3563 - accuracy: 0.8704
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
686/782 [=========================&gt;....] - ETA: 0s - loss: 0.3561 - accuracy: 0.8705
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
693/782 [=========================&gt;....] - ETA: 0s - loss: 0.3560 - accuracy: 0.8705
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
700/782 [=========================&gt;....] - ETA: 0s - loss: 0.3554 - accuracy: 0.8707
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
707/782 [==========================&gt;...] - ETA: 0s - loss: 0.3549 - accuracy: 0.8709
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
714/782 [==========================&gt;...] - ETA: 0s - loss: 0.3547 - accuracy: 0.8710
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
721/782 [==========================&gt;...] - ETA: 0s - loss: 0.3545 - accuracy: 0.8710
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
728/782 [==========================&gt;...] - ETA: 0s - loss: 0.3547 - accuracy: 0.8711
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
735/782 [===========================&gt;..] - ETA: 0s - loss: 0.3548 - accuracy: 0.8710
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
742/782 [===========================&gt;..] - ETA: 0s - loss: 0.3546 - accuracy: 0.8713
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
749/782 [===========================&gt;..] - ETA: 0s - loss: 0.3544 - accuracy: 0.8713
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
756/782 [============================&gt;.] - ETA: 0s - loss: 0.3541 - accuracy: 0.8713
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
763/782 [============================&gt;.] - ETA: 0s - loss: 0.3544 - accuracy: 0.8712
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
770/782 [============================&gt;.] - ETA: 0s - loss: 0.3540 - accuracy: 0.8712
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
777/782 [============================&gt;.] - ETA: 0s - loss: 0.3538 - accuracy: 0.8713
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
782/782 [==============================] - 6s 8ms/step - loss: 0.3540 - accuracy: 0.8713
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">to_json</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;{&quot;class_name&quot;: &quot;Sequential&quot;, &quot;config&quot;: {&quot;name&quot;: &quot;sequential_4&quot;, &quot;layers&quot;: [{&quot;class_name&quot;: &quot;InputLayer&quot;, &quot;config&quot;: {&quot;batch_input_shape&quot;: [null, 784], &quot;dtype&quot;: &quot;float32&quot;, &quot;sparse&quot;: false, &quot;ragged&quot;: false, &quot;name&quot;: &quot;dense_9_input&quot;}}, {&quot;class_name&quot;: &quot;Dense&quot;, &quot;config&quot;: {&quot;name&quot;: &quot;dense_9&quot;, &quot;trainable&quot;: true, &quot;batch_input_shape&quot;: [null, 784], &quot;dtype&quot;: &quot;float32&quot;, &quot;units&quot;: 512, &quot;activation&quot;: &quot;relu&quot;, &quot;use_bias&quot;: true, &quot;kernel_initializer&quot;: {&quot;class_name&quot;: &quot;HeNormal&quot;, &quot;config&quot;: {&quot;seed&quot;: null}}, &quot;bias_initializer&quot;: {&quot;class_name&quot;: &quot;Zeros&quot;, &quot;config&quot;: {}}, &quot;kernel_regularizer&quot;: null, &quot;bias_regularizer&quot;: null, &quot;activity_regularizer&quot;: null, &quot;kernel_constraint&quot;: null, &quot;bias_constraint&quot;: null}}, {&quot;class_name&quot;: &quot;Dense&quot;, &quot;config&quot;: {&quot;name&quot;: &quot;dense_10&quot;, &quot;trainable&quot;: true, &quot;dtype&quot;: &quot;float32&quot;, &quot;units&quot;: 512, &quot;activation&quot;: &quot;relu&quot;, &quot;use_bias&quot;: true, &quot;kernel_initializer&quot;: {&quot;class_name&quot;: &quot;HeNormal&quot;, &quot;config&quot;: {&quot;seed&quot;: null}}, &quot;bias_initializer&quot;: {&quot;class_name&quot;: &quot;Zeros&quot;, &quot;config&quot;: {}}, &quot;kernel_regularizer&quot;: null, &quot;bias_regularizer&quot;: null, &quot;activity_regularizer&quot;: null, &quot;kernel_constraint&quot;: null, &quot;bias_constraint&quot;: null}}, {&quot;class_name&quot;: &quot;Dense&quot;, &quot;config&quot;: {&quot;name&quot;: &quot;dense_11&quot;, &quot;trainable&quot;: true, &quot;dtype&quot;: &quot;float32&quot;, &quot;units&quot;: 10, &quot;activation&quot;: &quot;softmax&quot;, &quot;use_bias&quot;: true, &quot;kernel_initializer&quot;: {&quot;class_name&quot;: &quot;GlorotUniform&quot;, &quot;config&quot;: {&quot;seed&quot;: null}}, &quot;bias_initializer&quot;: {&quot;class_name&quot;: &quot;Zeros&quot;, &quot;config&quot;: {}}, &quot;kernel_regularizer&quot;: null, &quot;bias_regularizer&quot;: null, &quot;activity_regularizer&quot;: null, &quot;kernel_constraint&quot;: null, &quot;bias_constraint&quot;: null}}]}, &quot;keras_version&quot;: &quot;2.7.0&quot;, &quot;backend&quot;: &quot;tensorflow&quot;}&#39;
</pre></div>
</div>
</div>
</div>
<p>You can also specify a validation set so that the validation loss and accuracy is also returned.
‘verbose=0’ will silence the output prints.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">()</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xf_train</span><span class="p">,</span> <span class="n">yf_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-02-16 13:12:14.293619: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-02-16 13:12:24.971970: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.
</pre></div>
</div>
</div>
</div>
<p>The returned history contains evaluation data (loss and metrics) for every epoch</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history</span><span class="o">.</span><span class="n">history</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;loss&#39;: [0.5197401642799377, 0.4189545512199402, 0.3941621780395508],
 &#39;accuracy&#39;: [0.8128200769424438, 0.8555400371551514, 0.8626800775527954],
 &#39;val_loss&#39;: [0.5128745436668396, 0.41449621319770813, 0.4282766878604889],
 &#39;val_accuracy&#39;: [0.8355000615119934, 0.8568000197410583, 0.8627000451087952]}
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="predictions-and-evaluations">
<h3>Predictions and evaluations<a class="headerlink" href="#predictions-and-evaluations" title="Permalink to this headline">¶</a></h3>
<p>We can now call <code class="docutils literal notranslate"><span class="pre">predict</span></code> to generate predictions, and <code class="docutils literal notranslate"><span class="pre">evaluate</span></code> the trained model on the entire test set</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">network</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Visualize one of the predictions</span>
<span class="n">sample_id</span> <span class="o">=</span> <span class="mi">0</span>
<span class="nb">print</span><span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="n">sample_id</span><span class="p">])</span>

<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">axes</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">sample_id</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">gray_r</span><span class="p">)</span>
<span class="n">axes</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;True label: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">sample_id</span><span class="p">]))</span>
<span class="n">axes</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([])</span>
<span class="n">axes</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-02-16 13:12:50.951811: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[8.7031993e-10 7.9530329e-15 1.9035468e-10 3.1608715e-12 3.4167467e-12
 1.4762090e-05 3.8569441e-09 2.3013113e-04 1.8015553e-08 9.9975508e-01]
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[]
</pre></div>
</div>
<img alt="../_images/Lab 6 - Tutorial_43_3.png" src="../_images/Lab 6 - Tutorial_43_3.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test accuracy:&#39;</span><span class="p">,</span> <span class="n">test_acc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/313 [..............................] - ETA: 11s - loss: 0.2212 - accuracy: 0.9375
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 10/313 [..............................] - ETA: 1s - loss: 0.4358 - accuracy: 0.8500 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 18/313 [&gt;.............................] - ETA: 1s - loss: 0.4698 - accuracy: 0.8507
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 27/313 [=&gt;............................] - ETA: 1s - loss: 0.4291 - accuracy: 0.8588
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 36/313 [==&gt;...........................] - ETA: 1s - loss: 0.4210 - accuracy: 0.8681
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 45/313 [===&gt;..........................] - ETA: 1s - loss: 0.4239 - accuracy: 0.8646
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 54/313 [====&gt;.........................] - ETA: 1s - loss: 0.4231 - accuracy: 0.8628
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 63/313 [=====&gt;........................] - ETA: 1s - loss: 0.4437 - accuracy: 0.8601
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 72/313 [=====&gt;........................] - ETA: 1s - loss: 0.4261 - accuracy: 0.8611
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 81/313 [======&gt;.......................] - ETA: 1s - loss: 0.4238 - accuracy: 0.8603
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 90/313 [=======&gt;......................] - ETA: 1s - loss: 0.4210 - accuracy: 0.8580
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 99/313 [========&gt;.....................] - ETA: 1s - loss: 0.4258 - accuracy: 0.8583
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
108/313 [=========&gt;....................] - ETA: 1s - loss: 0.4269 - accuracy: 0.8573
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
117/313 [==========&gt;...................] - ETA: 1s - loss: 0.4312 - accuracy: 0.8582
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
126/313 [===========&gt;..................] - ETA: 1s - loss: 0.4336 - accuracy: 0.8569
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
135/313 [===========&gt;..................] - ETA: 1s - loss: 0.4338 - accuracy: 0.8553
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
144/313 [============&gt;.................] - ETA: 0s - loss: 0.4300 - accuracy: 0.8561
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
152/313 [=============&gt;................] - ETA: 0s - loss: 0.4296 - accuracy: 0.8559
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
161/313 [==============&gt;...............] - ETA: 0s - loss: 0.4304 - accuracy: 0.8564
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
170/313 [===============&gt;..............] - ETA: 0s - loss: 0.4328 - accuracy: 0.8561
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
179/313 [================&gt;.............] - ETA: 0s - loss: 0.4345 - accuracy: 0.8556
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
187/313 [================&gt;.............] - ETA: 0s - loss: 0.4339 - accuracy: 0.8565
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
196/313 [=================&gt;............] - ETA: 0s - loss: 0.4331 - accuracy: 0.8570
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
205/313 [==================&gt;...........] - ETA: 0s - loss: 0.4301 - accuracy: 0.8575
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
214/313 [===================&gt;..........] - ETA: 0s - loss: 0.4289 - accuracy: 0.8584
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
223/313 [====================&gt;.........] - ETA: 0s - loss: 0.4288 - accuracy: 0.8586
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
232/313 [=====================&gt;........] - ETA: 0s - loss: 0.4307 - accuracy: 0.8574
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
241/313 [======================&gt;.......] - ETA: 0s - loss: 0.4331 - accuracy: 0.8571
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
250/313 [======================&gt;.......] - ETA: 0s - loss: 0.4349 - accuracy: 0.8569
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
259/313 [=======================&gt;......] - ETA: 0s - loss: 0.4318 - accuracy: 0.8577
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
268/313 [========================&gt;.....] - ETA: 0s - loss: 0.4312 - accuracy: 0.8577
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
277/313 [=========================&gt;....] - ETA: 0s - loss: 0.4319 - accuracy: 0.8577
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
285/313 [==========================&gt;...] - ETA: 0s - loss: 0.4368 - accuracy: 0.8568
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
294/313 [===========================&gt;..] - ETA: 0s - loss: 0.4338 - accuracy: 0.8578
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
303/313 [============================&gt;.] - ETA: 0s - loss: 0.4311 - accuracy: 0.8583
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
312/313 [============================&gt;.] - ETA: 0s - loss: 0.4318 - accuracy: 0.8579
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
313/313 [==============================] - 2s 6ms/step - loss: 0.4326 - accuracy: 0.8577
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test accuracy: 0.8577000498771667
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="checking-the-learning-curve">
<h2>Checking the learning curve<a class="headerlink" href="#checking-the-learning-curve" title="Permalink to this headline">¶</a></h2>
<p>There are several ways to check the learning curve</p>
<ul class="simple">
<li><p>Wait until the training is finished, then plot the results in the returned history</p></li>
<li><p>Add a callback to the fit function that re-draws the learning curve in real time with every update</p>
<ul>
<li><p>An example implementation is given below</p></li>
</ul>
</li>
<li><p>Use an external tool such as <a class="reference external" href="https://www.tensorflow.org/tensorboard/get_started">TensorBoard</a></p></li>
<li><p>There are also commercial tools, e.g. <a class="reference external" href="https://www.wandb.com/">WeightsAndBiases</a></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">clear_output</span>

<span class="c1"># For plotting the learning curve in real time</span>
<span class="k">class</span> <span class="nc">TrainingPlot</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">):</span>
    
    <span class="c1"># This function is called when the training begins</span>
    <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="p">{}):</span>
        <span class="c1"># Initialize the lists for holding the logs, losses and accuracies</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">acc</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_acc</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_acc</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="c1"># This function is called at the end of each epoch</span>
    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="p">{}):</span>
        
        <span class="c1"># Append the logs, losses and accuracies to the lists</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;accuracy&#39;</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;val_loss&#39;</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_acc</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_acc</span><span class="p">,</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">))</span>
        
        <span class="c1"># Before plotting ensure at least 2 epochs have passed</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            
            <span class="c1"># Clear the previous plot</span>
            <span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">N</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">))</span>
            
            <span class="c1"># Plot train loss, train acc, val loss and val acc against epochs passed</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;train_loss&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">acc</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;train_acc&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_losses</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;val_loss&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_acc</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;val_acc&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Training Loss and Accuracy [Epoch </span><span class="si">{}</span><span class="s2">, Max Acc </span><span class="si">{:.4f}</span><span class="s2">]&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_acc</span><span class="p">))</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch #&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss/Accuracy&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">plot_losses</span> <span class="o">=</span> <span class="n">TrainingPlot</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">()</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xf_train</span><span class="p">,</span> <span class="n">yf_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">plot_losses</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Lab 6 - Tutorial_47_0.png" src="../_images/Lab 6 - Tutorial_47_0.png" />
</div>
</div>
<div class="section" id="early-stopping">
<h3>Early stopping<a class="headerlink" href="#early-stopping" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Stop training when the validation loss (or validation accuracy) no longer improves</p></li>
<li><p>Loss can be bumpy: use a moving average or wait for <span class="math notranslate nohighlight">\(k\)</span> steps without improvement</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">earlystop</span> <span class="o">=</span> <span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">earlystop</span><span class="p">])</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">callbacks</span>

<span class="n">earlystop</span> <span class="o">=</span> <span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">()</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xf_train</span><span class="p">,</span> <span class="n">yf_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">plot_losses</span><span class="p">,</span> <span class="n">earlystop</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Lab 6 - Tutorial_49_0.png" src="../_images/Lab 6 - Tutorial_49_0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="regularization">
<h2>Regularization<a class="headerlink" href="#regularization" title="Permalink to this headline">¶</a></h2>
<p>There are several ways that we can regularize our models it they are overfitting:</p>
<ul class="simple">
<li><p>Get more data</p></li>
<li><p>Make the network smaller (e.g. use fewer nodes in the layers, or use fewer layers)</p></li>
<li><p>Regularize the model weights (e.g. by L1/L2 regularization)</p></li>
<li><p>Dropout</p></li>
<li><p>Batch normalization also has a regularization effect</p></li>
</ul>
<div class="section" id="weight-regularization-weight-decay">
<h3>Weight regularization (weight decay)<a class="headerlink" href="#weight-regularization-weight-decay" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Weight regularization can be applied to layers using a <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/regularizers">kernel regularizer</a></p></li>
</ul>
<ul class="simple">
<li><p>L1 regularization: leads to <em>sparse networks</em> with many weights that are 0</p></li>
<li><p>L2 regularization: leads to many very small weights</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">regularizers</span>

<span class="n">earlystop</span> <span class="o">=</span> <span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">()</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xf_train</span><span class="p">,</span> <span class="n">yf_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">plot_losses</span><span class="p">,</span> <span class="n">earlystop</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Lab 6 - Tutorial_51_0.png" src="../_images/Lab 6 - Tutorial_51_0.png" />
</div>
</div>
</div>
<div class="section" id="dropout">
<h3>Dropout<a class="headerlink" href="#dropout" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Dropout randomly sets a number of layer activations to 0. This avoids that non-significant patterns are ‘memorized’ by the model.</p></li>
<li><p>It is added to the model via a <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout">Dropout layer</a></p></li>
<li><p>The <em>dropout rate</em> (the fraction of the outputs that are zeroed-out) is usually between 0.1 and 0.5, but should be tuned to the specific network.</p></li>
<li><p>You could add dropout after any dense layer.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="n">plot_losses</span> <span class="o">=</span> <span class="n">TrainingPlot</span><span class="p">()</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xf_train</span><span class="p">,</span> <span class="n">yf_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">plot_losses</span><span class="p">,</span> <span class="n">earlystop</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Lab 6 - Tutorial_53_0.png" src="../_images/Lab 6 - Tutorial_53_0.png" />
</div>
</div>
</div>
<div class="section" id="batch-normalization">
<h3>Batch Normalization<a class="headerlink" href="#batch-normalization" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Batch normalization normalizes the activations of the previous layer within each batch</p>
<ul>
<li><p>Within a batch, set the mean activation close to 0 and the standard deviation close to 1</p>
<ul>
<li><p>Across badges, use exponential moving average of batch-wise mean and variance</p></li>
</ul>
</li>
<li><p>Allows deeper networks less prone to vanishing or exploding gradients</p></li>
</ul>
</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">265</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="n">plot_losses</span> <span class="o">=</span> <span class="n">TrainingPlot</span><span class="p">()</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xf_train</span><span class="p">,</span> <span class="n">yf_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">plot_losses</span><span class="p">,</span> <span class="n">earlystop</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Lab 6 - Tutorial_56_0.png" src="../_images/Lab 6 - Tutorial_56_0.png" />
</div>
</div>
<div class="section" id="combining-multiple-regularizers">
<h4>Combining multiple regularizers<a class="headerlink" href="#combining-multiple-regularizers" title="Permalink to this headline">¶</a></h4>
<p>There is some debate about whether it makes sense to combine multiple regularizers, and in which order. What works (or not) depends on the structure and size of the network and the dataset at hand.</p>
<p>For instance, since Batch Normalization already does some regularization, Dropout may not be needed. However, in this case (see below), the combination does help. Sometimes it helps do use Dropout after Batch Normalization only in the deepest layers.</p>
<p>BatchNormalization is sometimes done before the Dense layer, but in general it works better if it is applied after the dense layer. Likewise, dropout can be applied before or after Batch Normalization. Using Dropout before Batch Normalization, however, will include 0’s in the normalization statistics, which is not ideal.
<a class="reference external" href="https://arxiv.org/pdf/1801.05134.pdf">Here is an interesting paper on this topic</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">network</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">265</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,)))</span>
<span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">))</span>
<span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">))</span>
<span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">))</span>
<span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
<span class="n">network</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="n">plot_losses</span> <span class="o">=</span> <span class="n">TrainingPlot</span><span class="p">()</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xf_train</span><span class="p">,</span> <span class="n">yf_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                      <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">plot_losses</span><span class="p">,</span> <span class="n">earlystop</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Lab 6 - Tutorial_58_0.png" src="../_images/Lab 6 - Tutorial_58_0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="tuning-multiple-hyperparameters">
<h3>Tuning multiple hyperparameters<a class="headerlink" href="#tuning-multiple-hyperparameters" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Keras has an associated tuning library, <a class="reference external" href="https://www.tensorflow.org/tutorials/keras/keras_tuner">keras-tuner</a>, with several tuning techniques:</p></li>
</ul>
<ul class="simple">
<li><p>RandomSearch</p></li>
<li><p>Hyperband</p></li>
<li><p>BayesianOptimization</p></li>
<li><p>Sklearn (for tuning scikit-learn models)</p></li>
</ul>
<p>We’ll cover Hyperband and Bayesian Optimization later.</p>
<p>Note: keras-tuner creates a folder with all results per ‘project’ (see the ‘project_name’ parameter).
You will need to remove the folder or change the project name to run it again.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install -q -U keras-tuner
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">optimizers</span>
<span class="kn">import</span> <span class="nn">keras_tuner</span> <span class="k">as</span> <span class="nn">kt</span>


<span class="k">def</span> <span class="nf">build_model</span><span class="p">(</span><span class="n">hp</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>

    <span class="c1"># Tune the number of units in the dense layers</span>
    <span class="c1"># Choose an optimal value between 32-512</span>
    <span class="n">hp_units</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">&#39;units&#39;</span><span class="p">,</span> <span class="n">min_value</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="n">max_value</span> <span class="o">=</span> <span class="mi">265</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mi">32</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span> <span class="o">=</span> <span class="n">hp_units</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span> <span class="o">=</span> <span class="n">hp_units</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>

    <span class="c1"># Tune the learning rate for the optimizer </span>
    <span class="c1"># Choose an optimal value from 0.01, 0.001, or 0.0001</span>
    <span class="n">hp_learning_rate</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="n">values</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1e-2</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">])</span> 

    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">hp_learning_rate</span><span class="p">),</span>
                  <span class="n">loss</span> <span class="o">=</span> <span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
                  <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="n">tuner</span> <span class="o">=</span> <span class="n">kt</span><span class="o">.</span><span class="n">RandomSearch</span><span class="p">(</span><span class="n">build_model</span><span class="p">,</span> <span class="n">max_trials</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">objective</span> <span class="o">=</span> <span class="s1">&#39;val_accuracy&#39;</span><span class="p">,</span> <span class="n">project_name</span><span class="o">=</span><span class="s1">&#39;lab7&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Uncomment to run. It takes a while.</span>
<span class="c1"># tuner.search(Xf_train, yf_train, epochs = 10, validation_data = (x_val, y_val), callbacks = [TrainingPlot()])</span>

<span class="c1"># Get the optimal hyperparameters</span>
<span class="c1">#best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>You can wrap Keras models as scikit-learn models using <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/wrappers/scikit_learn/KerasClassifier">KerasClassifier</a> and use any tuning technique</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.wrappers.scikit_learn</span> <span class="kn">import</span> <span class="n">KerasClassifier</span>

<span class="k">def</span> <span class="nf">build_model</span><span class="p">(</span><span class="n">var_activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span><span class="n">var_optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Uses arguments to build Keras model. &quot;&quot;&quot;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="n">var_activation</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="n">var_activation</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="n">var_activation</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">var_optimizer</span><span class="p">,</span>
                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="c1"># Search space</span>
<span class="n">_activations</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;tanh&#39;</span><span class="p">,</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span><span class="s1">&#39;selu&#39;</span><span class="p">]</span>
<span class="n">_optimizers</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;sgd&#39;</span><span class="p">,</span><span class="s1">&#39;adam&#39;</span><span class="p">]</span>
<span class="n">_batch_size</span><span class="o">=</span><span class="p">[</span><span class="mi">16</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">64</span><span class="p">]</span>
<span class="n">params</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">var_activation</span><span class="o">=</span><span class="n">_activations</span><span class="p">,</span>
            <span class="n">var_optimizer</span><span class="o">=</span><span class="n">_optimizers</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">_batch_size</span><span class="p">)</span>

<span class="c1"># Wrap</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">KerasClassifier</span><span class="p">(</span><span class="n">build_fn</span><span class="o">=</span><span class="n">build_model</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/var/folders/0t/5d8ttqzd773fy0wq3h5db0xr0000gn/T/ipykernel_60097/5830362.py:24: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.
  model = KerasClassifier(build_fn=build_model,epochs=4,batch_size=16)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RandomizedSearchCV</span>

<span class="c1"># Uncomment to run. It takes a while.</span>
<span class="c1">#rscv = RandomizedSearchCV(model, param_distributions=params, cv=3, n_iter=10, verbose=1, n_jobs=-1)</span>
<span class="c1">#rscv_results = rscv.fit(Xf_train,yf_train)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#print(&#39;Best score is: {} using {}&#39;.format(rscv_results.best_score_, rscv_results.best_params_))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="further-reading">
<h3>Further reading<a class="headerlink" href="#further-reading" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://www.tensorflow.org/learn">https://www.tensorflow.org/learn</a></p>
<p><a class="reference external" href="http://playground.tensorflow.org">http://playground.tensorflow.org</a></p>
<p><a class="reference external" href="https://www.tensorflow.org/tensorboard">https://www.tensorflow.org/tensorboard</a></p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./labs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="Lab%204%20-%20Tutorial.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Lab 4 Tutorial: Data engineering pipelines</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Lab%207%20-%20Tutorial.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Lab 7 Tutorial: Deep Learning for text</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Joaquin Vanschoren<br/>
    
        &copy; Copyright 2021. CC0 Licensed - Use as you like.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>